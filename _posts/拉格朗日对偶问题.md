---
title: 拉格朗日对偶问题
date: 2017-07-02 23:35:37
tags: [拉格朗日, 对偶问题]
categories: [数学理论, 高等数学]
comments: true 
toc: true
---


<img src="拉格朗日对偶问题/首图.png" width="350" height="200" />
><font color=#0000FF face="微软雅黑" size=4>Lagrange multiplier.</font>

### 1. 概述
#### 1.1 优化问题
&emsp;&emsp;<font color=#000000 size=5>**生**</font>活中总是存在着各种各样的最优化问题，比如出行的时候，不坐地铁的情况下（地铁贵啊！）如何坐车时间最省。工作上时间一定的情况下，如何安排任务能最快的完成。这些问题就是数学里面的约束最优化问题，按照约束类型和约束条件的不同，可以分成以下三大类：
<!--  more -->
&emsp;&emsp;1、零约束（无约束）最优化；
$$
\min \limits\_{} { f(x) } \ \ or \ \ \max \limits\_{} { f(x) } 
$$

&emsp;&emsp;2、一个及以上<font color='red'>**等式约束**</font>最优化（其中$h\_i(x)$表示第i个约束条件）；
$$
\min \limits\_{} { f(x) } \ \ or \ \ \max \limits\_{} { f(x) } \\\\
s.t \ \ h_i(x) = 0，i = 1, 2, ···, n
$$

&emsp;&emsp;3、一个及以上<font color='red'>**不等式约束**</font>最优化（同时还可以有等式约束）；
$$
\min \limits\_{} { f(x) } \ \ or \ \ \max \limits\_{} { f(x) } \\\\
\begin{split}
\textbf{s.t}\ \ h_i(x) & \geq 0（或h_i(x) \leq 0），i = 1，2，···，n \\\\
g_j(x) &= 0，j = 0，1，···，m
\end{split}
$$

#### 1.2 本文约定
&emsp;&emsp;为了叙述方便，我们仅对两种最优化问题（最大或最小）中的一种进行探讨，另一种其证明过程和原理是完全相同的，如无特殊说明，下文中的最优化问题都是指对目标函数求<font color='red'>**最小值**</font>，即：
$$
\min \limits\_{} { f(x) }
$$
#### 1.3 优化求解
&emsp;&emsp;针对以上三种优化问题，对应的求解方法如下：

##### 1.3.1 Fermat引理
&emsp;&emsp;对于第一种情况（零约束优化），高数里面我们就学过，通过求解函数的偏导数（partial derivative）并令其为零，然后结合Fermat引理即可求出最优值。

##### 1.3.2 Lagrange Multiplier
&emsp;&emsp;对于第二种情况（带等式约束优化），实际上在高中的时候我们就学过，通过增加拉格朗日系数，构造出拉格朗日函数，并对各个变量求导后令其为零，从而求解出各个变量的候选解集，最后回代并验证这些解集，最后求出最优值。这种方法就是广为人知的拉格朗日乘子法（Lagrange Multiplier）！

##### 1.3.3 Lagrange Multiplier + KKT Conditions
&emsp;&emsp;对于第三种情况（带不等式约束优化），可能大多数非数学专业的同学都没有接触过，需要结合KKT条件（KKT Conditions）来求解，这里就涉及到一个新的概念——KKT条件。为了更方便排版叙述，下面新开一个小节来说说这个KKT条件。

#### 1.4 KKT条件
##### 1.4.1 概述
&emsp;&emsp;KKT条件的全称是Karush–Kuhn–Tucker  conditions（也称Kuhn–Tucker conditions），多应用于数学中的优化问题（非线性最优化）。考虑如下的非线性（带不等式约束）最优化问题：
$$
\begin{split}
目标&函数：f(x) \\\\
约束&条件： \\\\
\ \ &g_i(x) \leq 0 \\\\
\ \ &h_j(x) = 0
\end{split}
$$

&emsp;&emsp;所谓KKT条件，是指对于最优解$x^\*$，其必然满足如下的必要条件：

##### 1.4.2 Stationarity
&emsp;&emsp;KKT条件的<font color="blue">Stationarity（即平稳性）</font>从最大化和最小化两个优化方向来说，对应如下的式子：
$$
\begin{cases}
最大化f(x)：\nabla f(x^\*) = { \sum\_{i=1}^m \mu\_i \nabla g\_i(x^\*)  + \sum\_{j=1}^l \lambda\_j \nabla h\_j(x^\*) }  \\\\
\\\\
\ 最小化f(x)：-\nabla f(x^\*) = { \sum\_{i=1}^m \mu\_i \nabla g\_i(x^\*)  + \sum\_{j=1}^l \lambda\_j \nabla h\_j(x^\*) }  \\\\
\tag{1 - 1}
\end{cases}
$$

##### 1.4.3 Primal feasibility
&emsp;&emsp;KKT条件的<font color="blue">Primal feasibility（原始可行性）</font>是指原始问题的约束条件：
$$
\begin{cases}
\begin{split}
g_i(x) & \leq 0，i = 1，···，m\\\\
h_j(x) &= 0，j = 1，···，l
\end{split}
\tag{1 - 2}
\end{cases}
$$

##### 1.4.4 Dual feasibility
&emsp;&emsp;KKT条件的<font color="blue">Dual feasibility（对偶可行性）</font>是指不等式约束条件的拉格朗日乘数应满足条件： 

$$
\mu_i(x) \geq 0 ，i = 1，···，m
\tag{1 - 3}
$$

##### 1.4.5 Complementary slackness
&emsp;&emsp;KKT条件的<font color="blue">Complementary slackness（互补松弛）</font>是指如下条件：
$$
\mu_i(x) g_i(x^\*) = 0 ，i = 1，···，m
\tag{1 - 4}
$$

&emsp;&emsp;上面的$\mu_i、\lambda_j$均称为拉格朗日乘数，**当KKT条件中的$m=0$时，即退化为拉格朗日条件**。


#### 1.5 广义拉格朗日函数
##### 1.5.1 表达式
&emsp;&emsp;为了在KKT条件下利用拉格朗日乘子求出最优值，我们需要构造出广义拉格朗日函数（**generalized Lagrange function**），以上述优化问题为例，其对应的广义拉格朗日函数为：

$$
L(x,\alpha,\beta) = f(x) + { \sum\_{i=1}^k \alpha\_i  g\_i(x) } +  { \sum\_{j=l}^k \beta\_j  h\_j(x) }
\tag{1 - 5}
$$

&emsp;&emsp;式中：
$$
\begin{cases}
\begin{split}
&& \alpha\_i,\beta\_j是拉格朗日乘子; \\\\
&& \alpha\_i \geq 0; 
\end{split}
\end{cases}
$$

##### 1.5.2 极小极大问题
&emsp;&emsp;可以证明（见后文相关部分），若原始问题和对偶问题均存在解，则它们的解是等价的（即有相同的解），上述最优化问题（称为**原始最优化问题**或**原始问题**等价于如下的广义拉格朗日函数的<font color='red'>**极小极大问题**</font>：
$$
\min \limits\_{x} {\theta\_P(x)} = \min \limits\_{x} {\max \limits\_{\alpha , \beta : \alpha\_i \geq 0} { L(x , \alpha , \beta) } }
\tag{ 1 - 6}
$$
&emsp;&emsp;这样就把原始最优化问题转换为了广义拉格朗日函数的极小极大问题。同样为了方便叙述，定义原始最优化问题的解为$p^\*$，即有：
$$
p^\* = \min \limits\_{x} {\theta\_P(x)} = \min \limits\_{x} {\max \limits\_{\alpha , \beta : \alpha\_i \geq 0} { L(x , \alpha , \beta) } }
\tag{ 1 - 7}
$$

#### 1.6 对偶问题
##### 1.6.1 定义
&emsp;&emsp;我们记如下广义拉格朗日函数的<font color='red'>**极大极大小问题（注意极大、极小两个词语的顺序和1.4节的不同）**</font>为上述最优化问题的对偶问题：
$$
\max \limits\_{\alpha , \beta , \alpha\_i \geq 0} {\theta\_D(\alpha , \beta)} = \max \limits\_{\alpha , \beta , \alpha\_i \geq 0} {\min \limits\_{x} { L(x , \alpha , \beta) } }
\tag{ 1 - 8}
$$
&emsp;&emsp;同时，记上述对偶问题的解为$d^\*$，即有：
$$
d^\* = \max \limits\_{\alpha , \beta , \alpha\_i \geq 0} {\theta\_D(\alpha , \beta)} = \max \limits\_{\alpha , \beta , \alpha\_i \geq 0} {\min \limits\_{x} { L(x , \alpha , \beta) } }
\tag{ 1 - 9}
$$

##### 1.6.2 二者关系
&emsp;&emsp;可以证明（见后文相关部分），若原始问题和对偶问题均存在解，则它们的解是等价的，即有：
$$
p^\* = \min \limits\_{x} {\theta\_P(x)} = \max \limits\_{\alpha , \beta , \alpha\_i \geq 0} {\theta\_D(\alpha , \beta)} = d^\*
\tag{ 1- 10}
$$


### 2. 证明详解
#### 2.1 KKT条件的理解
&emsp;&emsp;上面1.3节列出了KKT条件，式（1 - 1）的Stationarity条件看懂了吗？光看这个式子，让人对这个条件有点云里雾里，我们结合图形来说明就容易理解了。为简单起见，我们以三维坐标系为例，设函数为$z = f(x , y)$。

##### 2.1.1 函数等高线
&emsp;&emsp;假如我们将给定的函数式$z =  f(x , y)$绘制在三维平面坐标系中，该函数对应的图形为曲面（平面属于特殊曲面），当我们取特定的z值如$z = f(x , y) = 2$时，则是将该曲面上所有z坐标为2的点取出来，这些点构成的是一条曲线，我们注意到这条曲线上的所有点都有相同的z值，也即相同的“高”，因此我们称曲线$f(x , y) = c$为函数$f(x , y)$的**等高线**，如下草图所示：
<div style="text-align:center"  ><img src="拉格朗日对偶问题/函数及函数等高线.jpg"width="400" height="300" /> <i align='center'>图2-1　　函数及函数等高线</i> 
</div>

&emsp;&emsp;由图我们可知，如果$f(x , y) \in R^+$，那么函数的等高线是有无数条的。
##### 2.1.2 等高线的应用
&emsp;&emsp;介绍了等高线，那么有什么用呢。最优化问题可以转换为等高线之间的关系问题，下面我们先以一个最简单的最优化问题来说明，给定如下最优化问题：
$$
\begin{cases}
\min \limits\_{} { f(x , y) } \\\\
\begin{split}
\textbf{s.t}\ \ g(x , y) = c_1
\end{split}
\tag{ 2 - 1}
\end{cases}
$$
&emsp;&emsp;我们把上式（2 - 1）中的$f(x , y)、g(x , y) = c_1$绘制在三维坐标系中，可知前者是一个曲面，后者是另一个曲面上的一条等高线，如下草图所示：
<div style="text-align:center"  > <img src="拉格朗日对偶问题/最优化和等高线关系1.jpg" width="400" height="300" /> <i align='center'>图2-2　　最优化函数的三维图</i> 
</div>

&emsp;&emsp;原最优化问题用语言表达出来就是：在所有满足$g(x , y) = c_1$的点中，找出一个（或几个）点，使得$f(x , y)$最大。又因为$f(x , y)和g(x , y)$具有相同的自变量（$x、y$），因此从几何意义上来讲，就是将曲线$g(x , y) = c_1$上的点投影到曲面$f(x , y)$上，形成投影曲线$g'(x , y)$，然后找出该投影曲线上坐标值z最小的点，如下图所示：
<div style="text-align:center"  > <img src="拉格朗日对偶问题/最优化和等高线关系2.jpg"  width="400" height="300" /> <i align='center'>图2-3　　最优化函数的三维图2</i> 
</div>

&emsp;&emsp;<font color='red'>注意：曲线$g'(x , y)$只是曲面$f(x , y)$上的一条普通曲线，并不一定满足等高线特性。</font>
&emsp;&emsp;进一步，如果我们把曲面$f(x , y)$的所有等高线和约束等高线$g(x , y) = c_1$投影到X-Y平面上，那么最优化问题实际上就是找到曲面$f(x , y)$的所有等高线中与曲线$g(x , y) = c_1$<font color='red'>**相切**</font>的那条，<font color='red'>为什么不是相交？</font>因为相交就意味着还有其它等高线在这条等高线的内部或者外部与约束曲线相交，从而使得目标函数的值更小或更大，如下图所示：
<div style="text-align:center"  > <img src="拉格朗日对偶问题/最优化和等高线关系3.jpg"  width="400" height="300" /><i align='center'>图2-4　　等高线和约束曲线投影</i> 
</div>

&emsp;&emsp;如上图2-4所示，为了方便查看，我只画了三条目标函数的等高线投影，正如前面所述，并不代表我们的目标函数等高线只有三条！图中约束曲线和目标函数的所有等高线的交点$d_1、d_2、d_4、d_5$都不可能是最优化问题的解，只有$d_3$有可能成为最优值。

##### 2.1.3 梯度与最优化
&emsp;&emsp;光知道目标函数等高线和约束曲线相切还无法完全确定是最大值还是最小值，比如上图的点$d_3$，只看图2-4的话是无法下结论的，因为点$d_3$所在的等高线的Z值完全有可能比点$d_4$的大，从而不可能是最小值。这也是为什么地形图上不但要作出等高线，还要标注好高程。
&emsp;&emsp;如果不标注高程，那么图2-4所表示的山，既可能是上凸的（对应山尖），也可能是下凹的（对应山坳）。那么函数等高线又用什么来区分呢？答案就是：<font color='red'>**梯度**</font>！
&emsp;&emsp;对任意函数$f(x)$，其梯度可表示为：

$$
\nabla f(x) =  (\frac {\partial f}{\partial x\_1} , \frac {\partial f} {\partial x\_2}, ···, \frac {\partial f}{\partial x\_k}) ，k \in N^+
\tag{2 - 2}
$$

&emsp;&emsp;<font color='red'>**目标函数等高线和约束曲线的切点（候选最值点），它在目标函数上和约束函数上的梯度一定共线！**</font>即有：
$$
\nabla f(x_0) = \lambda \lbrack \nabla g(x_0) - c \rbrack =  \lambda  \nabla g(x_0)，\lambda \in R、\lambda \neq 0
\tag{2 - 3}
$$

&emsp;&emsp;式中，$x_0$表示切点。上式我们称为**梯度共线公式**，增加等式约束条件，我们就有多等式约束条件下的梯度共线公式：
$$
\nabla f(x_0) = \lambda_1  \nabla g_1(x_0) + \lambda_2  \nabla g_2(x_0) + ··· + \lambda_k  \nabla g_k(x_0)，k = 2,···
\tag{2 - 4}
$$
&emsp;&emsp;上式（2-4）是不是跟我们的Stationarity条件表达式（1-1）形式上一模一样了！但也仅仅只是形式上，还差那么一点点，因为式（1-1）是含有不等式约束的梯度共线公式，而式（2-4）是针对所有约束条件未等式的情况。