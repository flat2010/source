---
title: 机器学习算法系列之三：SVM（5）
date: 2018-03-31 16:01:10
tags: [机器学习, 算法, SVM, 支持向量机]
categories: [机器学习,  支持向量机] 
comments: true
toc: true
---
<img src="机器学习算法系列之三：SVM5/SVM5首图.png" width="430" height="200" />

><font color=#0000FF face="微软雅黑" size=4>水至清则无鱼！</font>

***

## 一、线性非可分
### 1.1 可分 *VS* 非可分
&emsp;&emsp;前面章节中我们讨论的分割面的求解均是在数据**线性可分**的条件下进行的，与该条件对应的数学表达式为：

$$
y_i \lgroup {\vec w} · \vec x_i + {b} \rgroup - 1  \geq 0, \ \ i = 1,2,···,N
\tag{1 - 1}
$$

&emsp;&emsp;这个限制条件对应的几何含义就是：**所有数据都能被准确的进行分类。**这个条件对我们简化问题，抽象出数学模型非常有用，但是在面对实际业务的时候却显得非常乏力，因为现实生活中我们所处理的数据几乎都是线性不可分甚至非线性的。这个时候如果不对式（1-1）做调整（改动）的话，会造成两方面的影响：

- 条件过于严格导致方程组在实数域无解，即找不到满足要求的分割面；
- 实数域中求出了分割面（训练数据集线性可分），但是模型泛化能力非常差（使用的时候遇到了线性非可分数据）。

&emsp;&emsp;以上问题，用一句古话总结就是：

> 水至清则无鱼 人至察则无徒

#### 1.1.1 相同点
&emsp;&emsp;线性可分和线性不可分二者建立起来的模型均是线性分类模型。
&emsp;&emsp;数学模型、理论基础是一致的，解决的技术方案（均转换为拉格朗日对偶问题解决）也相同。

#### 1.1.2 不同点
&emsp;&emsp;线性可分模型只能解决线性可分的问题，而线性非可分模型则可以解决所有线性问题（包含了线性可分、线性非可分）。
&emsp;&emsp;线性可分是基础，线性非可分是扩展。
&emsp;&emsp;线性可分使用硬间隔作为优化目标，线性非可分使用软间隔（引入了松弛变量、惩罚系数）作为优化目标。

### 1.2 解决之道
#### 1.2.1 松弛变量
&emsp;&emsp;为了让我们学习出的模型能够处理线性非可分数据，同时增强模型的泛化能力，我们就需要适当的放松间隔的限制条件。**允许少部分数据（噪点、离群点）到分割超平面的几何间隔小于1（位于缓冲地带），甚至为负（位于相反的类中）。**
&emsp;&emsp;因此，我们针对训练集中的每一个样本点都引入一个调控参数，根据需要来调节数据点到分割超平面的距离，这个参数称为**松弛变量$\xi\_i \geq 0$**。于是原来的不等式约束变为下式：

$$
y\_i(\vec w \cdot \vec x\_i + b) \geq 1 - \xi\_i
\tag{1 - 2}
$$

#### 1.2.2 惩罚参数
&emsp;&emsp;引入松弛变量之后，线性非可分问题倒是解决了，却又引入了新的问题。